{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMTlffe6Oou0",
        "outputId": "6e79efb4-c7ec-4a6c-f446-b376bdb7bd6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'GAN-Group6' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Kaleb-Huneau/GAN-Group6.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOPMrqb4G1zo"
      },
      "source": [
        "Preprocessing: for the brain MRI dataset [Brain tumor MRI](https://github.com/masoudnick/Brain-Tumor-MRI-Classification/blob/main/Preprocessing.py)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s-vPtX0IGxqA"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'cv2'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[0;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mimutils\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import os\n",
        "import imutils\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def make_directory(PATH):\n",
        "\tif not os.path.exists(PATH):\n",
        "\t\tos.mkdir(PATH)\n",
        "\n",
        "def crop_img(img):\n",
        "\t\"\"\"\n",
        "\tFinds the extreme points on the image and crops the rectangular out of them\n",
        "\t\"\"\"\n",
        "\tgray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\tgray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
        "\n",
        "\t# threshold the image, then perform a series of erosions +\n",
        "\t# dilations to remove any small regions of noise\n",
        "\tthresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
        "\tthresh = cv2.erode(thresh, None, iterations=2)\n",
        "\tthresh = cv2.dilate(thresh, None, iterations=2)\n",
        "\n",
        "\t# find contours in thresholded image, then grab the largest one\n",
        "\tcnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\tcnts = imutils.grab_contours(cnts)\n",
        "\tc = max(cnts, key=cv2.contourArea)\n",
        "\n",
        "\t# find the extreme points\n",
        "\textLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
        "\textRight = tuple(c[c[:, :, 0].argmax()][0])\n",
        "\textTop = tuple(c[c[:, :, 1].argmin()][0])\n",
        "\textBot = tuple(c[c[:, :, 1].argmax()][0])\n",
        "\tADD_PIXELS = 0\n",
        "\tnew_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()\n",
        "\n",
        "\treturn new_img\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\ttraining = 'GAN-Group6/Dataset/Training'\n",
        "\ttesting = 'GAN-Group6/Dataset/Testing'\n",
        "\n",
        "\tmake_directory(training)\n",
        "\tmake_directory(testing)\n",
        "\n",
        "\tIMG_SIZE = 128\n",
        "\n",
        "\t# Now, list the directories after creating them\n",
        "\ttraining_dir = os.listdir(training)\n",
        "\ttesting_dir = os.listdir(testing)\n",
        "\ttumors = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]\n",
        "\n",
        "\tfor dir in tumors:\n",
        "\t\t\tsave_path = 'cleaned4/Training/' + dir\n",
        "\t\t\tpath = os.path.join(training, dir)\n",
        "\t\t\timage_dir = os.listdir(path)\n",
        "\t\t\tfor img in image_dir:\n",
        "\t\t\t\t\timage = cv2.imread(os.path.join(path, img))\n",
        "\t\t\t\t\tnew_img = crop_img(image)\n",
        "\t\t\t\t\tnew_img = cv2.resize(new_img, (IMG_SIZE, IMG_SIZE))\n",
        "\t\t\t\t\tnew_img = cv2.cvtColor(new_img, cv2.COLOR_BGR2GRAY)\n",
        "\t\t\t\t\tif not os.path.exists(save_path):\n",
        "\t\t\t\t\t\t\tos.makedirs(save_path)\n",
        "\t\t\t\t\tcv2.imwrite(os.path.join(save_path, img), new_img)\n",
        "     \n",
        "\tfor dir in tumors:\n",
        "\t\t\tsave_path = 'cleaned4/Testing/' + dir\n",
        "\t\t\tpath = os.path.join(testing, dir)\n",
        "\t\t\timage_dir = os.listdir(path)\n",
        "\t\t\tfor img in image_dir:\n",
        "\t\t\t\t\timage = cv2.imread(os.path.join(path, img))\n",
        "\t\t\t\t\tnew_img = crop_img(image)\n",
        "\t\t\t\t\tnew_img = cv2.resize(new_img, (IMG_SIZE, IMG_SIZE))\n",
        "\t\t\t\t\tnew_img = cv2.cvtColor(new_img, cv2.COLOR_BGR2GRAY)\n",
        "\t\t\t\t\tif not os.path.exists(save_path):\n",
        "\t\t\t\t\t\t\tos.makedirs(save_path)\n",
        "\t\t\t\t\tcv2.imwrite(os.path.join(save_path, img), new_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvShI0YFGzgQ"
      },
      "source": [
        "GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3UjyGGOemqe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import tensorflow as tf\n",
        "#import tensorflow_probability as tfp\n",
        "from keras.initializers import RandomNormal\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, BatchNormalization, \\\n",
        "    LeakyReLU, Conv2DTranspose, Conv2D, Dropout, \\\n",
        "        Flatten, Reshape, ReLU, Input, Concatenate\n",
        "from keras import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers import Activation\n",
        "from tensorflow.python.data import Iterator\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "import sys\n",
        "import multiprocessing\n",
        "import argparse\n",
        "import matplotlib.pyplot as plt\n",
        "#import stacked_mnist\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "IMG_SIZE = 128\n",
        "\n",
        "#tfd = tfp.distributions\n",
        "\n",
        "def make_directory(PATH):\n",
        "    if not os.path.exists(PATH):\n",
        "            os.mkdir(PATH)\n",
        "\n",
        "\n",
        "class AlphaGAN(object):\n",
        "    def __init__(self, opt):\n",
        "        self.opt = opt\n",
        "        self.batch_size = 1\n",
        "        self.noise_dim = 128*128\n",
        "        self.epsilon = 1e-8\n",
        "        self.alpha_d = float(opt.alpha_d)\n",
        "        self.alpha_g = float(opt.alpha_g)\n",
        "        self.seed = opt.seed\n",
        "        self.loss_type = opt.loss_type\n",
        "        self.dataset = opt.dataset\n",
        "        self.n_epochs = opt.n_epochs\n",
        "        self.gp = opt.gp\n",
        "        self.scores = np.zeros(self.n_epochs)\n",
        "        self.num_images = opt.num_images\n",
        "        self.gp_coef = opt.gp_coef\n",
        "        if self.dataset != 'cifar10':\n",
        "            self.num_images = 10\n",
        "        self.d_opt = Adam(2e-4, beta_1 = 0.5)\n",
        "        self.g_opt = Adam(2e-4, beta_1 = 0.5)\n",
        "        if self.dataset == 'cifar10':\n",
        "            self.noise_dim = 100\n",
        "        self.l1 = opt.l1\n",
        "        tf.random.set_seed(self.seed)\n",
        "        np.random.seed(self.seed)\n",
        "\n",
        "\n",
        "    def get_data(self):\n",
        "        if self.dataset == 'mnist':\n",
        "            (self.train_img, _), (self.test_img, _) = tf.keras.datasets.mnist.load_data()\n",
        "            self.train_img = self.train_img.reshape(self.train_img.shape[0], 28, 28, 1)\n",
        "            self.test_img = self.test_img.reshape(self.test_img.shape[0], 28, 28, 1)\n",
        "\n",
        "        elif self.dataset == 'cifar10':\n",
        "            (self.train_img, _), (self.test_img, _) = tf.keras.datasets.cifar10.load_data()\n",
        "            self.train_img = self.train_img.reshape(self.train_img.shape[0], 32, 32, 3)\n",
        "            self.test_img = self.test_img.reshape(self.test_img.shape[0], 32, 32, 3)\n",
        "\n",
        "        elif self.dataset == 'stacked-mnist':\n",
        "            (self.train_img, _), (self.test_img, _) = stacked_mnist.load_data()\n",
        "            self.train_img = self.train_img.reshape(self.train_img.shape[0], 32, 32, 3)\n",
        "            self.test_img = self.test_img.reshape(self.test_img.shape[0], 32, 32, 3)\n",
        "\n",
        "        elif self.dataset == 'mri':\n",
        "            # Iterate over all files in the tumor directory\n",
        "\n",
        "            tumor_dir = '/Users/oscar/Desktop/virtualEnvs/AGAN/AlphaGANMRI/v5/cleaned4/Training/notumor'\n",
        "            tumor_training_images = []\n",
        "            for filename in os.listdir(tumor_dir):\n",
        "                if filename.endswith('.jpg'):  # Assuming images are in JPG format\n",
        "                    image_path = os.path.join(tumor_dir, filename)\n",
        "                    image = plt.imread(image_path, format='jpg')\n",
        "                    tumor_training_images.append(image)\n",
        "\n",
        "            # Convert the list of images to a NumPy array\n",
        "            self.train_img = np.asarray(tumor_training_images)\n",
        "\n",
        "            tumor_dir = '/Users/oscar/Desktop/virtualEnvs/AGAN/AlphaGANMRI/v5/cleaned4/Testing/notumor'\n",
        "            tumor_testing_images = []\n",
        "            for filename in os.listdir(tumor_dir):\n",
        "                if filename.endswith('.jpg'):  # Assuming images are in JPG format\n",
        "                    image_path = os.path.join(tumor_dir, filename)\n",
        "                    image = plt.imread(image_path, format='jpg')\n",
        "                    tumor_testing_images.append(image)\n",
        "\n",
        "            # Convert the list of images to a NumPy array\n",
        "            self.test_img = np.asarray(tumor_testing_images)\n",
        "\n",
        "            self.train_img = self.train_img.reshape(self.train_img.shape[0], IMG_SIZE, IMG_SIZE, 1)\n",
        "            self.test_img = self.test_img.reshape(self.test_img.shape[0], IMG_SIZE, IMG_SIZE, 1)\n",
        "\n",
        "          # self.train_img =  np.asarray([plt.imread(\"cleaned4/Training/notumor/Tr-noTr_0000.jpg\", format='jpg')])\n",
        "          # self.test_img = np.asarray([plt.imread(\"cleaned4/Testing/notumor/Te-noTr_0000.jpg\", format='jpg')])\n",
        "\n",
        "        self.real_mu, self.real_sigma = self.get_eval_metrics(self.train_img)\n",
        "        self.train_data, self.test_data = self.clean_data(self.train_img, train = True), self.clean_data(self.test_img, train = False)\n",
        "\n",
        "\n",
        "    def get_eval_metrics(self, data):\n",
        "        img_dims = data.shape\n",
        "        eval_img = data[np.random.choice(img_dims[0], 1, replace=False), :, :, :]\n",
        "        eval_img = eval_img.reshape(1, np.prod(img_dims[1:])).astype('float32') # CHANGE BACK TO 10000\n",
        "        eval_img = eval_img / 255.0\n",
        "        real_mu = eval_img.mean(axis = 0)\n",
        "        eval_img = np.transpose(eval_img)\n",
        "        real_sigma = np.cov(eval_img)\n",
        "        return real_mu, real_sigma\n",
        "\n",
        "    def clean_data(self, data, train):\n",
        "\n",
        "        new_data = data.astype('float32')\n",
        "        new_data = (new_data - 127.5) / 127.5\n",
        "        if train:\n",
        "            new_data = tf.data.Dataset.from_tensor_slices(new_data)\n",
        "            return new_data.shuffle(100000).batch(self.batch_size)\n",
        "        return new_data\n",
        "\n",
        "    def gen_loss_vanilla(self):\n",
        "        bce = tf.keras.losses.BinaryCrossentropy(from_logits = False)\n",
        "        loss_expr =  bce(tf.ones_like(self.fake_predicted_labels), self.fake_predicted_labels)\n",
        "        if self.l1:\n",
        "            loss_expr = tf.math.abs(loss_expr - (-tf.math.log(2.0)))\n",
        "        return loss_expr\n",
        "\n",
        "    def gen_loss_vanilla_l1(self):\n",
        "        return tf.math.abs(self.gen_loss_vanilla() - (-tf.math.log(2.0)))\n",
        "\n",
        "\n",
        "    def gen_loss_alpha(self):\n",
        "        fake_expr = tf.math.pow(1 - self.fake_predicted_labels, ((self.alpha_g-1)/self.alpha_g)*tf.ones_like(self.fake_predicted_labels))\n",
        "        fake_loss = tf.math.reduce_mean(fake_expr)\n",
        "        loss_expr = (self.alpha_g/(self.alpha_g - 1))*(fake_loss - 2.0)\n",
        "        if self.l1:\n",
        "            equil_val = (self.alpha_g)/(self.alpha_g - 1)*(tf.math.pow(2.0, 1/self.alpha_g) - 2)\n",
        "            loss_expr = tf.math.abs(loss_expr - equil_val)\n",
        "        return loss_expr\n",
        "\n",
        "    def dis_loss_vanilla(self):\n",
        "        bce = tf.keras.losses.BinaryCrossentropy(from_logits = False)\n",
        "        real_loss = bce(tf.ones_like(self.real_predicted_labels), self.real_predicted_labels)\n",
        "        fake_loss = bce(tf.zeros_like(self.fake_predicted_labels), self.fake_predicted_labels)\n",
        "        r1_penalty = 0\n",
        "        if self.gp:\n",
        "            gradients = tf.gradients(-tf.math.log(1 / self.real_predicted_labels - 1), [self.img])[0]\n",
        "            r1_penalty = tf.reduce_mean(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3]))\n",
        "        return real_loss + fake_loss + self.gp_coef*r1_penalty\n",
        "\n",
        "    def dis_loss_alpha(self):\n",
        "        real_expr = tf.math.pow(self.real_predicted_labels, ((self.alpha_d-1)/self.alpha_d)*tf.ones_like(self.real_predicted_labels))\n",
        "        real_loss = tf.math.reduce_mean(real_expr)\n",
        "        fake_expr = tf.math.pow(1 - self.fake_predicted_labels, ((self.alpha_d-1)/self.alpha_d)*tf.ones_like(self.fake_predicted_labels))\n",
        "        fake_loss = tf.math.reduce_mean(fake_expr)\n",
        "        r1_penalty = 0\n",
        "        if self.gp:\n",
        "            gradients = tf.gradients(-tf.math.log(1 / self.real_predicted_labels - 1), [self.img])[0]\n",
        "            r1_penalty = tf.reduce_mean(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3]))\n",
        "        loss_expr = -(self.alpha_d/(self.alpha_d - 1))*(real_loss + fake_loss - 2.0)\n",
        "\n",
        "\n",
        "        return loss_expr + self.gp_coef*r1_penalty\n",
        "\n",
        "\n",
        "    def build_generator(self):\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        if self.dataset == 'mnist':\n",
        "\n",
        "            model.add(Dense(7 * 7 * 256, use_bias=False, kernel_initializer=\n",
        "            RandomNormal(mean=0.0, stddev=0.01), input_shape=(self.noise_dim,)))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(LeakyReLU())\n",
        "\n",
        "            model.add(Reshape((8, 8, 256)))\n",
        "\n",
        "\n",
        "            model.add(Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False, kernel_initializer=\n",
        "            RandomNormal(mean=0.0, stddev=0.01)))\n",
        "\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(LeakyReLU())\n",
        "\n",
        "            model.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False, kernel_initializer=\n",
        "            RandomNormal(mean=0.0, stddev=0.01)))\n",
        "\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(LeakyReLU())\n",
        "\n",
        "            model.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', activation='tanh', use_bias=False,\n",
        "                                        kernel_initializer=RandomNormal(mean=0.0, stddev=0.01)))\n",
        "\n",
        "\n",
        "        elif self.dataset == 'cifar10' or self.dataset == 'stacked-mnist':\n",
        "            model.add(Dense(256*4*4, input_shape=(self.noise_dim,)))\n",
        "            model.add(LeakyReLU(0.2))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(Reshape((4, 4, 256)))\n",
        "\n",
        "            model.add(Conv2DTranspose(128, (4,4), strides = (2,2), padding = 'same'))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(LeakyReLU(0.2))\n",
        "\n",
        "            model.add(Conv2DTranspose(128, (4,4), strides = (2,2), padding = 'same'))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(LeakyReLU(0.2))\n",
        "\n",
        "            model.add(Conv2DTranspose(128, (4,4), strides = (2,2), padding = 'same'))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(LeakyReLU(0.2))\n",
        "\n",
        "            model.add(Conv2D(3, (3, 3), activation='tanh', padding = 'same'))\n",
        "\n",
        "        elif self.dataset == 'mri':\n",
        "            model.add(Dense(8 * 8 * 256, use_bias=False, kernel_initializer=\n",
        "            RandomNormal(mean=0.0, stddev=0.01), input_shape=(self.noise_dim,)))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(LeakyReLU())\n",
        "\n",
        "            model.add(Reshape((8, 8, 256)))\n",
        "\n",
        "\n",
        "            model.add(Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False, kernel_initializer=\n",
        "            RandomNormal(mean=0.0, stddev=0.01)))\n",
        "\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(LeakyReLU())\n",
        "\n",
        "            model.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False, kernel_initializer=\n",
        "            RandomNormal(mean=0.0, stddev=0.01)))\n",
        "\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(LeakyReLU())\n",
        "\n",
        "            #added extra conv2dtranspose to upsize to 64\n",
        "            model.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False, kernel_initializer=\n",
        "            RandomNormal(mean=0.0, stddev=0.01)))\n",
        "\n",
        "            #added extra conv2dtranspose to upsize to 128\n",
        "            model.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False, kernel_initializer=\n",
        "            RandomNormal(mean=0.0, stddev=0.01)))\n",
        "\n",
        "            # #added extra conv2dtranspose to upsize to 256\n",
        "            # model.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False, kernel_initializer=\n",
        "            # RandomNormal(mean=0.0, stddev=0.01)))\n",
        "\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(LeakyReLU())\n",
        "\n",
        "\n",
        "\n",
        "            model.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', activation='tanh', use_bias=False,\n",
        "                                        kernel_initializer=RandomNormal(mean=0.0, stddev=0.01)))\n",
        "\n",
        "        return model\n",
        "\n",
        "\n",
        "    def build_dq(self):\n",
        "\n",
        "        model = Sequential()\n",
        "        if self.dataset == 'mnist':\n",
        "            model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same', kernel_initializer=\n",
        "            RandomNormal(mean=0.0, stddev=0.01)))\n",
        "            model.add(LeakyReLU())\n",
        "            model.add(Dropout(0.3))\n",
        "\n",
        "            model.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same', kernel_initializer=\n",
        "            RandomNormal(mean=0.0, stddev=0.01)))\n",
        "            model.add(LeakyReLU())\n",
        "            model.add(Dropout(0.3))\n",
        "\n",
        "            model.add(Flatten())\n",
        "            model.add(Dense(1, activation='sigmoid', kernel_initializer=\n",
        "            RandomNormal(mean=0.0, stddev=0.01)))\n",
        "\n",
        "        elif self.dataset == 'cifar10' or self.dataset == 'stacked-mnist':\n",
        "            model.add(Conv2D(64, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
        "            model.add(LeakyReLU(0.2))\n",
        "\n",
        "            model.add(Conv2D(128, (3, 3), strides = (2, 2), padding = 'same'))\n",
        "            model.add(LeakyReLU(0.2))\n",
        "\n",
        "            model.add(Conv2D(128, (3, 3), strides = (2, 2), padding = 'same'))\n",
        "            model.add(LeakyReLU(0.2))\n",
        "\n",
        "            model.add(Conv2D(256, (3, 3), strides = (2, 2), padding = 'same'))\n",
        "            model.add(LeakyReLU(0.2))\n",
        "\n",
        "            model.add(Flatten())\n",
        "            model.add(Dropout(0.4))\n",
        "            model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "        elif self.dataset == 'mri':\n",
        "            model.add(Conv2D(64, (3, 3), padding='same', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
        "            model.add(LeakyReLU(0.2))\n",
        "\n",
        "            model.add(Conv2D(128, (3, 3), strides = (2, 2), padding = 'same'))\n",
        "            model.add(LeakyReLU(0.2))\n",
        "\n",
        "            model.add(Conv2D(128, (3, 3), strides = (2, 2), padding = 'same'))\n",
        "            model.add(LeakyReLU(0.2))\n",
        "\n",
        "            model.add(Conv2D(256, (3, 3), strides = (2, 2), padding = 'same'))\n",
        "            model.add(LeakyReLU(0.2))\n",
        "\n",
        "            model.add(Flatten())\n",
        "            model.add(Dropout(0.4))\n",
        "            model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "        return model\n",
        "\n",
        "    def build_gan(self):\n",
        "        self.generator = self.build_generator()\n",
        "        self.discriminator = self.build_dq()\n",
        "        self.generator_loss = self.gen_loss_alpha\n",
        "        self.discriminator_loss = self.dis_loss_alpha\n",
        "        if self.alpha_d == 1.0:\n",
        "            self.discriminator_loss = self.dis_loss_vanilla\n",
        "        if self.alpha_g == 1.0:\n",
        "            self.generator_loss = self.gen_loss_vanilla\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(self, real_images):\n",
        "\n",
        "        z = tf.random.normal([self.batch_size, self.noise_dim])\n",
        "        with tf.GradientTape() as gen_tape, tf.GradientTape() as dis_tape, tf.GradientTape() as q_tape:\n",
        "            self.discriminator.trainable = True\n",
        "            self.img = real_images\n",
        "            self.real_predicted_labels = self.discriminator(real_images, training = True)\n",
        "\n",
        "            self.generated_images = self.generator(z, training = True)\n",
        "            self.fake_predicted_labels = self.discriminator(self.generated_images, training = True)\n",
        "\n",
        "            self.dis_loss_value = self.discriminator_loss()\n",
        "            self.gen_loss_value = self.generator_loss()\n",
        "\n",
        "        dis_gradients = dis_tape.gradient(self.dis_loss_value, self.discriminator.trainable_variables)\n",
        "        self.d_opt.apply_gradients(zip(dis_gradients, self.discriminator.trainable_variables))\n",
        "        self.discriminator.trainable = False\n",
        "        gen_gradients = gen_tape.gradient(self.gen_loss_value, self.generator.trainable_variables)\n",
        "        self.g_opt.apply_gradients(zip(gen_gradients, self.generator.trainable_variables))\n",
        "\n",
        "        return self.dis_loss_value, self.gen_loss_value\n",
        "\n",
        "    def build_directory(self):\n",
        "        gan_name = 'AlphaGAN'\n",
        "        if self.alpha_d == 1.0 and self.alpha_g == 1.0:\n",
        "            gan_name = 'VanillaGAN'\n",
        "        '''\n",
        "        SEEDS = [123, 1600, 60677, 15859, 79878]\n",
        "        if self.dataset == 'mnist':\n",
        "            SEEDS = [123, 500, 1600, 199621, 60677, 20435, 15859, 33764, 79878, 36123]\n",
        "        '''\n",
        "        make_directory(gan_name)\n",
        "        make_directory(f'{gan_name}/{self.dataset}')\n",
        "        if gan_name == 'AlphaGAN':\n",
        "            make_directory(f'{gan_name}/{self.dataset}/alpha-d{self.alpha_d}-g{self.alpha_g}')\n",
        "\n",
        "        subfolders = [f[0] for f in os.walk(f'AlphaGAN/{self.dataset}/alpha-d{self.alpha_d}-g{self.alpha_g}')]\n",
        "        folders = [f for f in subfolders if f.startswith(f'AlphaGAN/{self.dataset}/alpha-d{self.alpha_d}-g{self.alpha_g}/v')]\n",
        "\n",
        "        versions = [f.split('/v')[1] for f in folders]\n",
        "        versions = [int(v) for v in versions if v.isnumeric()]\n",
        "        version = 1\n",
        "        if versions:\n",
        "            version = max(versions) + 1\n",
        "        folder_created = False\n",
        "\n",
        "        while not folder_created:\n",
        "            self.path = f'AlphaGAN/{self.dataset}/alpha-d{self.alpha_d}-g{self.alpha_g}/v'+str(version)\n",
        "\n",
        "            try:\n",
        "                make_directory(self.path)\n",
        "                folder_created = True\n",
        "            except:\n",
        "                version += 1\n",
        "        '''\n",
        "\n",
        "        version = SEEDS.index(self.seed) + 1\n",
        "        if self.gp and self.l1:\n",
        "            version = version + 15 if self.dataset != 'mnist' else version + 30\n",
        "        elif self.gp:\n",
        "            version = version + 5 if self.dataset != 'mnist' else version + 10\n",
        "        elif self.l1:\n",
        "            version = version + 10 if self.dataset != 'mnist' else version + 20\n",
        "        '''\n",
        "        self.path = f'{gan_name}/{self.dataset}/alpha-d{self.alpha_d}-g{self.alpha_g}/v'+str(version)\n",
        "        if gan_name == 'VanillaGAN':\n",
        "            self.path = f'{gan_name}/{self.dataset}/v'+str(version)\n",
        "\n",
        "        make_directory(self.path)\n",
        "        make_directory(self.path + '/metrics')\n",
        "        make_directory(self.path + '/metrics/accuracy')\n",
        "        make_directory(self.path + '/metrics/losses')\n",
        "        make_directory(self.path + '/img')\n",
        "        make_directory(self.path + '/models')\n",
        "\n",
        "        with open(self.path+'/description.txt', 'w') as f:\n",
        "            f.write(f'version={version}\\n')\n",
        "            for k, v in vars(self.opt).items():\n",
        "                f.write(f'{k}={v}')\n",
        "                f.write('\\n')\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        self.get_data()\n",
        "        self.build_gan()\n",
        "        self.build_directory()\n",
        "        gen_loss_history = np.zeros(self.n_epochs)\n",
        "        dis_loss_history = np.zeros(self.n_epochs)\n",
        "        epoch_times = []\n",
        "        img_times = []\n",
        "        epochs_passed = 0\n",
        "        for epoch in range(1, self.n_epochs + 1):\n",
        "            print(f\"Epoch {epoch}\")\n",
        "            n_batches = 0\n",
        "            start_epoch = time.time()\n",
        "            for real_images in iter(self.train_data):\n",
        "\n",
        "                dis_loss_value, gen_loss_value = self.train_step(real_images)\n",
        "\n",
        "                gen_loss_history[epoch - 1] += gen_loss_value\n",
        "                dis_loss_history[epoch - 1] += dis_loss_value\n",
        "\n",
        "                n_batches += 1\n",
        "            gen_loss_history = gen_loss_history/n_batches\n",
        "            dis_loss_history = dis_loss_history/n_batches\n",
        "            end_epoch = time.time()\n",
        "            epoch_times.append(end_epoch - start_epoch)\n",
        "            # self.evaluate(epoch)\n",
        "            start_img = time.time()\n",
        "            self.save_generated_images(epoch)\n",
        "            end_img = time.time()\n",
        "            img_times.append(end_img - start_img)\n",
        "            epochs_passed += 1\n",
        "\n",
        "            if epochs_passed % 100 == 0:\n",
        "                gan.save_generated_images(1)\n",
        "\n",
        "            # try:\n",
        "            #     self.scores[epoch - 1] = self.compute_fid()\n",
        "            # except Exception as e:\n",
        "            #     print(str(e))\n",
        "            #     break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        np.save(self.path + '/metrics/losses/gen_loss.npy', gen_loss_history)\n",
        "        np.save(self.path + '/metrics/losses/dis_loss.npy', dis_loss_history)\n",
        "\n",
        "        self.generator.save(self.path+ '/models/generator')\n",
        "        self.discriminator.save(self.path + '/models/discriminator')\n",
        "\n",
        "        time_df = pd.DataFrame({'epoch':list(range(1, epochs_passed + 1)),\n",
        "        'epoch_time':epoch_times, 'img_times':img_times})\n",
        "\n",
        "        time_df.to_pickle(self.path+'/times.pkl')\n",
        "        np.save(self.path + '/scores.npy', self.scores)\n",
        "        if epochs_passed == self.n_epochs:\n",
        "            for epoch in range(epochs_passed):\n",
        "                if epoch != np.nanargmin(self.scores):\n",
        "                    os.remove(self.path + '/img/predictions' + str(epoch + 1) + \".npy\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def compute_fid(self):\n",
        "        fake_images = self.generator(tf.random.normal([10000, self.noise_dim]))\n",
        "        fake_images = fake_images.numpy()\n",
        "        if self.dataset == 'mnist' or self.dataset == 'mri':\n",
        "            fake_images = fake_images.reshape(10000, 28*28)\n",
        "        elif self.dataset == 'cifar10':\n",
        "            fake_images = fake_images.reshape(10000, 32*32*3)\n",
        "        elif self.dataset == 'stacked-mnist':\n",
        "            fake_images = fake_images.reshape(10000, 32*32*3)\n",
        "        fake_images = (fake_images * 127.5 + 127.5) / 255.0\n",
        "        fake_mu = fake_images.mean(axis=0)\n",
        "        fake_sigma = np.cov(np.transpose(fake_images))\n",
        "        covSqrt = sp.linalg.sqrtm(np.matmul(fake_sigma, self.real_sigma))\n",
        "        if np.iscomplexobj(covSqrt):\n",
        "            covSqrt = covSqrt.real\n",
        "        fidScore = np.linalg.norm(self.real_mu - fake_mu) + np.trace(self.real_sigma + fake_sigma - 2 * covSqrt)\n",
        "        return fidScore\n",
        "\n",
        "\n",
        "\n",
        "    def save_generated_images(self, epoch):\n",
        "        if epoch == 1:\n",
        "            self.z_eval = tf.random.normal([self.num_images, self.noise_dim])\n",
        "\n",
        "\n",
        "        imgs = self.generator(self.z_eval, training = False)\n",
        "        print(imgs.shape)\n",
        "\n",
        "        np.save(self.path+'/img/predictions' + str(epoch) + '.npy', imgs)\n",
        "\n",
        "        return\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dgzhqre-e707",
        "outputId": "0af1308c-bbe5-4775-a63b-e799f9ef4ec9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/fq/n7jswqss1ll4c6l_f9fmq5f00000gn/T/ipykernel_81607/965251073.py:119: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  real_sigma = np.cov(eval_img)\n",
            "/Users/oscar/Desktop/virtualEnvs/AGAN/AlphaGANMRI/lib/python3.12/site-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/Users/oscar/Desktop/virtualEnvs/AGAN/AlphaGANMRI/lib/python3.12/site-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n",
            "/Users/oscar/Desktop/virtualEnvs/AGAN/AlphaGANMRI/lib/python3.12/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/Users/oscar/Desktop/virtualEnvs/AGAN/AlphaGANMRI/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39m#build the generative network\u001b[39;00m\n\u001b[1;32m     43\u001b[0m gan\u001b[39m.\u001b[39mbuild_gan()\n\u001b[0;32m---> 45\u001b[0m gan\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     47\u001b[0m gan\u001b[39m.\u001b[39msave_generated_images(\u001b[39m1\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[39m# while testing not going to include fid computations\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39m# gan.compute_fid()\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[4], line 434\u001b[0m, in \u001b[0;36mAlphaGAN.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    431\u001b[0m start_epoch \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    432\u001b[0m \u001b[39mfor\u001b[39;00m real_images \u001b[39min\u001b[39;00m \u001b[39miter\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_data):\n\u001b[0;32m--> 434\u001b[0m     dis_loss_value, gen_loss_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step(real_images)\n\u001b[1;32m    436\u001b[0m     gen_loss_history[epoch \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m gen_loss_value\n\u001b[1;32m    437\u001b[0m     dis_loss_history[epoch \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m dis_loss_value\n",
            "File \u001b[0;32m~/Desktop/virtualEnvs/AGAN/AlphaGANMRI/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/Desktop/virtualEnvs/AGAN/AlphaGANMRI/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m~/Desktop/virtualEnvs/AGAN/AlphaGANMRI/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:869\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    867\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    868\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 869\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    870\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[1;32m    871\u001b[0m   )\n\u001b[1;32m    872\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[0;32m~/Desktop/virtualEnvs/AGAN/AlphaGANMRI/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
            "File \u001b[0;32m~/Desktop/virtualEnvs/AGAN/AlphaGANMRI/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[0;32m~/Desktop/virtualEnvs/AGAN/AlphaGANMRI/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_preflattened\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_flat(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    217\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
            "File \u001b[0;32m~/Desktop/virtualEnvs/AGAN/AlphaGANMRI/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    253\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
            "File \u001b[0;32m~/Desktop/virtualEnvs/AGAN/AlphaGANMRI/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1501\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1502\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1503\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1504\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1505\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1506\u001b[0m   )\n\u001b[1;32m   1507\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
            "File \u001b[0;32m~/Desktop/virtualEnvs/AGAN/AlphaGANMRI/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#from keras.datasets import mnist\n",
        "import gc\n",
        "import argparse\n",
        "\n",
        "class Option():\n",
        "    \"\"\"\n",
        "    Empty class to hold the gan options\n",
        "    \"\"\"\n",
        "    def __init__(self, gan_type, alpha, seed, c_type, n_epochs, dataset, loss_type, lambda_d, lambda_c, num_images, gp, gen_lr, dis_lr, q_lr, gp_coef, alpha_d, alpha_g, k, shifted, l1):\n",
        "        self.gan_type = gan_type\n",
        "        self.alpha = alpha\n",
        "        self.seed = seed\n",
        "        self.c_type = c_type\n",
        "        self.n_epochs = n_epochs\n",
        "        self.dataset = dataset\n",
        "        self.loss_type = loss_type\n",
        "        self.lambda_d = lambda_d\n",
        "        self.lambda_c = lambda_c\n",
        "        self.num_images = num_images\n",
        "        self.gp = gp\n",
        "        self.gen_lr = gen_lr\n",
        "        self.dis_lr = dis_lr\n",
        "        self.q_lr = q_lr\n",
        "        self.gp_coef = gp_coef\n",
        "        self.alpha_d = alpha_d\n",
        "        self.alpha_g = alpha_g\n",
        "        self.k = k\n",
        "        self.shifted = shifted\n",
        "        self.l1 = l1\n",
        "        return\n",
        "#set up options\n",
        "opts = Option(gan_type='alpha', alpha=3.0, seed=42, c_type='discrete', n_epochs=3, dataset='mri', loss_type='vanilla', lambda_d=1.0, lambda_c=0.1, num_images=1, gp=False, gen_lr=0.0002, dis_lr=0.0002, q_lr=0.0002, gp_coef=5.0, alpha_d=3.0, alpha_g=3.0, k=2.0, shifted=False, l1=False)\n",
        "\n",
        "# Define an alphagan to test\n",
        "gan = AlphaGAN(opts)\n",
        "\n",
        "# sets data to mnist and configures it for the gan\n",
        "gan.dataset = 'mri'\n",
        "gan.get_data()\n",
        "\n",
        "\n",
        "#build the generative network\n",
        "gan.build_gan()\n",
        "\n",
        "gan.train()\n",
        "\n",
        "gan.save_generated_images(1)\n",
        "\n",
        "# while testing not going to include fid computations\n",
        "# gan.compute_fid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "auYhEuVnfrG7",
        "outputId": "a59770c7-bb3b-4d03-e9fd-1ac4d45f6e5e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "filename = \"/Users/oscar/Desktop/Queens/Year 4/virtualEnvs/AGAN/AlphaGANMRI/predictions218.npy\"\n",
        "# Load the numpy file\n",
        "img_array = np.load(filename, allow_pickle=True)\n",
        "\n",
        "# Normalize the data to [0, 1]\n",
        "img_array_normalized = (img_array - img_array.min()) / (img_array.max() - img_array.min())\n",
        "\n",
        "# Add the channel dimension back\n",
        "img_array_normalized_with_channel = img_array_normalized[0, :, :, 0]\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(img_array_normalized_with_channel, cmap=\"gray\")\n",
        "plt.axis('off')  # Turn off axis labels\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCl3PekMfqZ5"
      },
      "outputs": [],
      "source": [
        "img = plt.imread(\"cleaned/Training/notumor/Tr-noTr_0000.jpg\", format='jpg')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
